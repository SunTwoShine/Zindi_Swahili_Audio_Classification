{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4a37fa-b84f-4817-8032-836129e7ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import IPython.display as ipd\n",
    "from matplotlib import pyplot as plt\n",
    "import librosa\n",
    "import librosa.display\n",
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc64974-e22c-4f29-8725-dd1f0c2aa71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52a5bac-cf5d-49a0-8fc8-b740a352cb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load files\n",
    "train = pd.read_csv('data/Train.csv')\n",
    "test = pd.read_csv('data/Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d8ffec-5f47-4a58-97d6-3d4e94b797be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going from a sound to an image: spectrograms\n",
    "# os.mkdir('data/spectrograms_filter') # Create a folder to store the spectrograms\n",
    "\n",
    "# Function to generate spectrogram\n",
    "def gen_spectrogram(path):\n",
    "    x , sr = librosa.load(path)\n",
    "    # ind_max = x.argmax()\n",
    "    # x_2sec = x[ind_max-sr:ind_max+sr]\n",
    "    X = librosa.stft(x) #librosa.stft(x_2sec)\n",
    "    Xdb = librosa.amplitude_to_db(np.abs(X), ref=np.max)\n",
    "    fig = plt.figure(frameon=False)\n",
    "    fig.set_size_inches(8, 8)\n",
    "    ax = plt.Axes(fig, [0., 0., 1., 1.])\n",
    "    ax.set_axis_off()\n",
    "    fig.add_axes(ax)\n",
    "    # plt.title('Swahili Word - Nane')\n",
    "    librosa.display.specshow(Xdb, y_axis='log', x_axis='time', sr=sr)\n",
    "    spec_path = 'data/spectrograms_filter/' + path.split('/')[2][:-4] +'.png'\n",
    "    fig.savefig(spec_path, dpi=512//8)\n",
    "\n",
    "gen_spectrogram('data/Swahili_words_filtered/id_pwvzavl2dl6q.wav')\n",
    "display(ipd.Audio('data/Swahili_words_filtered/id_pwvzavl2dl6q.wav'))\n",
    "\n",
    "\n",
    "# show the three files of each word time-centered in frequency domain\n",
    "# for word in dict_samples:\n",
    "#     i=0\n",
    "#     fig, ax = plt.subplots(nrows=1, ncols=3, sharey=True)\n",
    "#     fig.set_size_inches(10, 5)\n",
    "#     fig.suptitle(word)\n",
    "#     for audiofile in dict_samples[word]:\n",
    "#         x, sr = librosa.load('data/Swahili_words/'+audiofile)\n",
    "#         # filtering +-1sec around the loudest part, centering the wavefiles to spoken word \n",
    "#         ind_max = x.argmax()\n",
    "#         x_2sec = x[ind_max-sr:ind_max+sr]\n",
    "#         X = librosa.amplitude_to_db(np.abs(librosa.stft(x_2sec)), ref=np.max)\n",
    "#         img = librosa.display.specshow(X, y_axis='log', x_axis='time', sr=sr, ax=ax[i])\n",
    "#         i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e045d58-467d-496f-8338-624f9e6e8210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train with test for easy data manipulation\n",
    "train_test_files = train.Word_id.tolist() + test.Word_id.tolist()\n",
    "\n",
    "for word_id in tqdm(train_test_files):\n",
    "  # Check if we've already generated a spectrogram, and if not, make one\n",
    "    spec_path = 'data/spectrograms_filter/' + word_id[:-4] +'.png'\n",
    "    if not os.path.isfile(spec_path):\n",
    "        plt.clf()\n",
    "        gen_spectrogram('data/Swahili_words_filtered/'+ word_id)\n",
    "    ipd.clear_output(wait=True)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56bae9e4-1a82-47c7-a540-923c6af9238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking that the spectrograms were generated successfully:\n",
    "len(os.listdir('data/Swahili_words_filtered')) == len(os.listdir('data/spectrograms_filter')), len(os.listdir('data/spectrograms_filter'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189ee3bf-2301-4c51-b345-7d2ab49aa0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add spectrogram path to train set\n",
    "train['spec_name'] = [x.split('.')[0] + '.png' for x in train.Word_id]\n",
    "\n",
    "# Preview train\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bddee75-bf72-498a-a53e-2fce93ca630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcacf0e-d917-409e-87ce-f0357720dc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataloaders\n",
    "dls = ImageDataLoaders.from_df(train, fn_col='spec_name', label_col='Swahili_word', \n",
    "                               folder='data/spectrograms_filter', item_tfms=Resize(400),\n",
    "                               batch_tfms = aug_transforms(max_rotate=0, max_warp=0, size=224))\n",
    "dls.show_batch() # Note the augmentation applied to the images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae478721-287d-4602-8a18-6db821599405",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = vision_learner(dls, resnet34, metrics=error_rate)\n",
    "learn.fine_tune(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb2deab-f1be-4a30-8b78-f23e23e79079",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)\n",
    "interp.plot_top_losses(9, figsize=(15,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "092f7ac4-4c0e-4bd3-abdd-48b4f192f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "interp.plot_confusion_matrix(figsize=(6,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdcd5f9-677d-493e-8fcb-a55d78ae5c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('data/Test.csv')\n",
    "test['spec_name'] = [x.split('.')[0] + '.png' for x in test['Word_id']]\n",
    "\n",
    "preds, _ = learn.get_preds(dl=dls.test_dl(test)) \n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1307ae5b-787c-449c-a1e1-04a166cb972a",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.dls.vocab # The labels in the order used by the model (alphabetical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd368f7-633d-47f9-9e3e-7e8aa4f6c0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'Word_id': test['Word_id']})\n",
    "for i, label in enumerate(learn.dls.vocab):\n",
    "    submission[label] = preds[:,i].numpy()\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93334c4c-f8fa-4867-9b4c-ebf4e0812d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('data/submission_filter2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bbf847-632f-43f7-b1ef-7f64b450ca57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
